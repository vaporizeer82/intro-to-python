{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"Lab_2_functions.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2: Statistical analysis of data using numpy\n",
    "\n",
    "Lab slides: https://docs.google.com/presentation/d/1ykwwcQ0onMvAjUxfJmKl9tbo-rJPdB5pRwDEmpDsd-g/edit?usp=sharing\n",
    "\n",
    "For this lab the goal is to write functions to pull out one data channel and print out statistics for failed versus successful picks. This will involve using your function from the lecture activity to get just the data you want, then another function to do the statistics (essentially the **calc_stats** function from the lecture activity). \n",
    "\n",
    "Written properly, you only need one function to do stats for the entire data channel, just the succesful ones, or just the unsuccessful ones. For any data channel. In the homework you'll use these functions to do this for all of the data and write it back out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries that we need to import - numpy and json (for loading the description file)\n",
    "import numpy as np\n",
    "import json as json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Reading in data\n",
    "\n",
    "TODO Copy over code to do the following:\n",
    "- read in the numerical data and pull out the numerical data and the successful/unsuccessful data\n",
    "- create a boolean index variable for the successful picks\n",
    "\n",
    "Note: For this lab I'm going to \"hard-wire\" all of the numbers (number of time steps, number of data dimensions, etc) to make testing easier. When you move this code over to the homework you'll replace all of the hard-wired numbers with the variables you're calculating in homework 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_data = np.loadtxt('Data/proxy_pick_data.csv',dtype=float,delimiter=\",\")\n",
    "pick_data = np.loadtxt('Data/proxy_pick_data.csv',dtype=float,delimiter=\",\")\n",
    "pick_channel_data =pick_data[:,:-1]\n",
    "pick_successful = pick_data[:,-1]\n",
    "b_successful = np.array(pick_successful,dtype = bool)\n",
    "\n",
    "# Hard-wiring these values for the testing code\n",
    "n_timesteps = 40\n",
    "n_picks = 660\n",
    "n_total_dims = 33\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>get_data</pre></strong> passed! 💯</p>"
      ],
      "text/plain": [
       "get_data results: All test cases passed!"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"get_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Doing the slice\n",
    "\n",
    "Get the data for one of the channels. \n",
    "\n",
    "TODO: Copy over your function **get_channel_data** from lecture activity 2. Note: if your code did not handle doing 1, 2, or 3 dimensions, now you'll need it to. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# This reads in the json data\n",
    "try:\n",
    "    with open(\"Data/proxy_data_description.json\", \"r\") as fp:\n",
    "        pick_data_description = json.load(fp)\n",
    "except FileNotFoundError:\n",
    "    print(f\"The file was not found; check that the data directory is in the current one and the file is in that directory\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: Copy get_channel_data over to here\n",
    "def get_channel_data(all_data, n_picks, start_index, n_time_steps, n_total_dims, n_dims):\n",
    "    \"\"\" Get the data for just one channel (eg, wrist torque)\n",
    "    @param all_data - the pick_channel_data numpy array\n",
    "    @param n_picks - number of picks (number of rows in all_data)\n",
    "    @param start_index - where to start getting data from \n",
    "    @param n_time_steps - number of time steps\n",
    "    @param n_total_dims - what the skip value is - the total number of channels\n",
    "    @param n_dims - total number of dimensions to use (1, 2, or 3)\n",
    "    @return Return array should be n_picks X (n_timesteps * n_dims)\"\"\"\n",
    "\n",
    "    # TODO Your slice code goes here. Note that I kept most of the variable names the same, so you should only have\n",
    "    #  to change the wrist torque specific ones\n",
    "   \n",
    "    channel_data = np.zeros((n_picks, n_time_steps * n_dims))\n",
    "    channel_data[0:n_picks,0:n_time_steps] = pick_channel_data[:, start_index::n_total_dims]\n",
    "    if n_dims >= 2:\n",
    "        channel_data[:, 1::3] = pick_channel_data[:, start_index+1::n_total_dims]\n",
    "        channel_data[:, 2::3] = pick_channel_data[:, start_index+2::n_total_dims]\n",
    "\n",
    "# this should be changed to a for loop but is working currently\n",
    "\n",
    "    return channel_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test 1 - the wrist torque data using hard-wired values\n",
    "wrist_torque_start_index = 3\n",
    "n_dims_wrist_torque = 3\n",
    "\n",
    "wrist_torque_data = get_channel_data(pick_channel_data, \n",
    "                                     n_picks=n_picks, \n",
    "                                     start_index=wrist_torque_start_index,\n",
    "                                     n_time_steps=n_timesteps,\n",
    "                                     n_total_dims=n_total_dims,\n",
    "                                     n_dims=n_dims_wrist_torque)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SELF TESTS\n",
    "# Feel free to copy over the asserts from lecture activity 2 to debug the above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tests for Motor effort finger 1\n",
    "motor_effort_f1_start_index = 14\n",
    "n_dims_motor_effort_f1 = 1\n",
    "motor_effort_f1_data = get_channel_data(pick_channel_data, \n",
    "                                        n_picks=n_picks, \n",
    "                                        start_index=motor_effort_f1_start_index,\n",
    "                                        n_time_steps=n_timesteps,\n",
    "                                        n_total_dims=n_total_dims,\n",
    "                                        n_dims=n_dims_motor_effort_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check size and first, last element\n",
    "assert(motor_effort_f1_data.shape == (n_picks, n_timesteps * n_dims_motor_effort_f1))\n",
    "assert(np.isclose(motor_effort_f1_data[0, 0], 0.0))\n",
    "assert(np.isclose(motor_effort_f1_data[-1, -1], 51.11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "660\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>check_slice</pre></strong> passed! 🙌</p>"
      ],
      "text/plain": [
       "check_slice results: All test cases passed!"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(pick_channel_data.shape[0])\n",
    "grader.check(\"check_slice\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Compute stats: Write a function to calculate the four stats\n",
    "\n",
    "This is a variation on what you did in lab 1; in this case, we're going to do it with two functions. The first calculates the stats and returns the dictionary (**calc_stats**) the second does the **for** loop to make one dictionary for each dimension in the data.\n",
    "\n",
    "- Step 1 [this problem] - do the **calc_stats** function\n",
    "- Step 2 [next problem] - do the loop to calculate the stats for each x,y,z channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_stats(data):\n",
    "    \"\"\"Calculate min, max, mean and standard deviation for the array and put in a dictionary\n",
    "    @param data a numpy array\n",
    "    @return a dictionary\"\"\"\n",
    "\n",
    "    # Use keys Min, Max, Mean, and SD\n",
    "    my_dict = {\"Min\" : np.min(data),\n",
    "              \"Max\" : np.max(data),\n",
    "              \"Mean\" : np.mean(data), \n",
    "              \"SD\": np.std(data) }\n",
    "    return my_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Test the function with known data\n",
    "test_data = np.linspace(0, 1, 10)\n",
    "ret_dict = calc_stats(test_data)\n",
    "\n",
    "assert(np.isclose(ret_dict[\"Min\"], 0.0))\n",
    "assert(np.isclose(ret_dict[\"Max\"], 1.0))\n",
    "assert(np.isclose(ret_dict[\"Mean\"], 0.5))\n",
    "assert(np.isclose(ret_dict[\"SD\"], 0.319, atol=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>stats_channel</pre></strong> passed! 🌟</p>"
      ],
      "text/plain": [
       "stats_channel results: All test cases passed!"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"stats_channel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Now do the second half - \n",
    "\n",
    "This function calculates the stats for an entire channel of the data, and stores the result in a list of dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_stats_for_channel(data, n_dims):\n",
    "    \"\"\" Calculate the stats for a channel\n",
    "    @param data - an n_picks X n_timesteps * n_dims size rray\n",
    "    @param n_dims - 1, 2, or 3 (just x, or x,y, and z)\n",
    "    @return A list of dictionaries. The list is the lenght of n_dims\"\"\"\n",
    "\n",
    "    stats_list = []\n",
    "    # TODO Copy in your for loop from the statistics problem in Lab 1\n",
    "    # - You do NOT need to get the data out from pick data - it's done for you\n",
    "    # - You DO need to slice the data into the x,y,z channels\n",
    "    # - You need to loop n_dims times\n",
    "    # - Don't forget to return the array\n",
    "    x_slice = data[:, 0::n_dims]\n",
    "    if n_dims >= 2:\n",
    "        y_slice = data[:, 1::n_dims]\n",
    "        z_slice = data[:, 2::n_dims]\n",
    "\n",
    "        print(x_slice.shape)\n",
    "\n",
    "    if n_dims == 1:\n",
    "        all_slices = np.array([x_slice])\n",
    "    else:\n",
    "        all_slices = np.array([x_slice,y_slice,z_slice])\n",
    "    print(all_slices.shape)\n",
    "\n",
    "    for i in range(all_slices.shape[0]):\n",
    "        my_dict = {\"Min\" : np.min(all_slices[i,:,:]),\n",
    "                \"Max\" : np.max(all_slices[i,:,:]),\n",
    "                \"Mean\" : np.mean(all_slices[i,:,:]),\n",
    "                \"SD\": np.std(all_slices[i,:,:]) }\n",
    "        stats_list.append(my_dict)\n",
    "    print(stats_list)\n",
    "    return stats_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SCRATCH CELL\n",
    "# If you're having trouble, try setting n_dims to 1 and use test_data for the data input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 4)\n",
      "(3, 5, 4)\n",
      "[{'Min': 1.0, 'Max': 1.0, 'Mean': 1.0, 'SD': 0.0}, {'Min': 2.0, 'Max': 2.0, 'Mean': 2.0, 'SD': 0.0}, {'Min': 3.0, 'Max': 3.0, 'Mean': 3.0, 'SD': 0.0}]\n"
     ]
    }
   ],
   "source": [
    "# Testing with known data - make a fake data set with 5 picks, 4 time steps, and x, y, z data\n",
    "#  \n",
    "test_stats = np.zeros((5, 4 * 3))\n",
    "# Set the x data to be ones\n",
    "test_stats[:, 0::3] = np.ones((5, 4))\n",
    "# Set the y data to be twos\n",
    "test_stats[:, 1::3] = np.ones((5, 4)) * 2\n",
    "# Set the z data to be threes\n",
    "test_stats[:, 2::3] = np.ones((5, 4)) * 3\n",
    "\n",
    "# Now get the actual stats\n",
    "ret_stats_array = calc_stats_for_channel(test_stats, n_dims=3)\n",
    "\n",
    "# Check the mean result for x, y, and z - should be 1, 2, and 3 respectively\n",
    "assert(ret_stats_array[0][\"Mean\"] == 1.0)\n",
    "assert(ret_stats_array[1][\"Mean\"] == 2.0)\n",
    "assert(ret_stats_array[2][\"Mean\"] == 3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(660, 40)\n",
      "(3, 660, 40)\n",
      "[{'Min': -0.995878292, 'Max': 1.070451089, 'Mean': -0.08034154168640152, 'SD': 0.16572799217195466}, {'Min': -1.24642742, 'Max': 0.607428456, 'Mean': -0.08235645442053031, 'SD': 0.1825844421076967}, {'Min': -0.62552044, 'Max': 0.340460618, 'Mean': 0.01800652827314394, 'SD': 0.12296693121622884}]\n"
     ]
    }
   ],
   "source": [
    "# this should work - you can check the result against the values in Data/HW1_check_results.json\n",
    "ret_stats_wrist_torque = calc_stats_for_channel(wrist_torque_data, n_dims_wrist_torque)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 660, 40)\n",
      "[{'Min': -330.8699951, 'Max': 174.8500061, 'Mean': 35.32253659580265, 'SD': 33.617106097552536}]\n"
     ]
    }
   ],
   "source": [
    "# As should this\n",
    "res_stats_motor_effort_f1 = calc_stats_for_channel(motor_effort_f1_data, n_dims_motor_effort_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>loop_data_calc_stats</pre></strong> passed! 💯</p>"
      ],
      "text/plain": [
       "loop_data_calc_stats results: All test cases passed!"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"loop_data_calc_stats\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Boolean slicing to get successful versus unsuccessful statistics out\n",
    "\n",
    "Use the functions you just wrote - plus the boolean index you made at the beginning - to get out the min and max z values for successful versus unsuccessful picks. \n",
    "\n",
    "For this problem I have written code that is *incorrect*. You know the functions themselves are correct - you just tested them. The following bits of code have something wrong with either the way the function is called OR with the way the results are gotten back.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(355, 40)\n",
      "(3, 355, 40)\n",
      "[{'Min': -0.995878292, 'Max': 0.632657241, 'Mean': -0.07780834972429576, 'SD': 0.15833816521660998}, {'Min': -1.24642742, 'Max': 0.607428456, 'Mean': -0.0796942166728169, 'SD': 0.1669326700600358}, {'Min': -0.293665094, 'Max': 0.340460618, 'Mean': 0.010519443599788734, 'SD': 0.12105133264820692}]\n",
      "(660, 120)\n",
      "(660,)\n",
      "(305, 40)\n",
      "(3, 305, 40)\n",
      "[{'Min': -0.780959042, 'Max': 1.070451089, 'Mean': -0.08329001101934426, 'SD': 0.17388785665493053}, {'Min': -0.701354968, 'Max': 0.506712789, 'Mean': -0.08545512458590164, 'SD': 0.19921496676357384}, {'Min': -0.62552044, 'Max': 0.326538637, 'Mean': 0.026721003876557375, 'SD': 0.12459433689364202}]\n",
      "Successful: Minimum [{'Min': -0.995878292, 'Max': 0.632657241, 'Mean': -0.07780834972429576, 'SD': 0.15833816521660998}, {'Min': -1.24642742, 'Max': 0.607428456, 'Mean': -0.0796942166728169, 'SD': 0.1669326700600358}, {'Min': -0.293665094, 'Max': 0.340460618, 'Mean': 0.010519443599788734, 'SD': 0.12105133264820692}] and maximum 0.340460618 value of wrist torque z channel\n",
      "Unsuccessful: Minimum -0.62552044 and maximum 0.326538637 value of wrist torque z channel\n"
     ]
    }
   ],
   "source": [
    "# Use b_successful to pick out the rows that are successful. Send all column data for the selected rows.\n",
    "#   Wrist torque data has 3 dimensions (x,y,z)\n",
    "#   There's two errors here - one that actually will create incorrect results, one that just *happens* to work\n",
    "#   correctly, although it doesn't do what the first sentance says...\n",
    "ret_wrist_torque_successful = calc_stats_for_channel(wrist_torque_data[b_successful,:], n_dims=3)\n",
    "\n",
    "print(wrist_torque_data.shape)\n",
    "print(b_successful.shape)\n",
    "\n",
    "# The minimum should be in the third (last) element in the list, the \"min\" key\n",
    "z_min_successful = ret_wrist_torque_successful[2][\"Min\"]\n",
    "z_max_successful = ret_wrist_torque_successful[2][\"Max\"]\n",
    "\n",
    "# Use b_successful NOT true to pick out the picks that are successful.\n",
    "#  This generates a weird error - it's because not does not work over a numpy array. Try b_successful == False instead\n",
    "ret_wrist_torque_unsuccessful = calc_stats_for_channel(wrist_torque_data[b_successful==False,:], n_dims=3)\n",
    "\n",
    "# The minimum should be in the third (last) element in the list, the \"min\" key\n",
    "z_min_unsuccessful = ret_wrist_torque_unsuccessful[2][\"Min\"]\n",
    "# Why copying and pasting and changing variable names can cause problems...\n",
    "z_max_unsuccessful = ret_wrist_torque_unsuccessful[2][\"Max\"]\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Successful: Minimum {ret_wrist_torque_successful} and maximum {z_max_successful} value of wrist torque z channel\")\n",
    "print(f\"Unsuccessful: Minimum {z_min_unsuccessful} and maximum {z_max_unsuccessful} value of wrist torque z channel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>boolean_slicing</pre></strong> passed! 🍀</p>"
      ],
      "text/plain": [
       "boolean_slicing results: All test cases passed!"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"boolean_slicing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Optional/Extra credit: print out all of the indices where the maximum value for the successful pick was reached\n",
    "\n",
    "See the tutorial on **np.where**\n",
    "\n",
    "TODO: Use **np.where** to pick out the row, col pair that has the maximum z value of the successful pick\n",
    "\n",
    "Partial credit for picking out any row, col that has the maximum z value in **wrist_torque_data**, full extra credit for only printing out the row, col indices of successful picks with that *z* value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[99], line 9\u001b[0m\n\u001b[0;32m      4\u001b[0m all_rows_with_max \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Look at JUST the z values in wrist_torque_data\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m (\u001b[38;5;28mlen\u001b[39m(ret_wrist_torque_successful\u001b[38;5;241m.\u001b[39mcolumns)):\n\u001b[0;32m     10\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m (\u001b[38;5;28mlen\u001b[39m(ret_wrist_torque_successful)):\n\u001b[0;32m     11\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m ret_wrist_torque_successful[r,c]\u001b[38;5;241m==\u001b[39mret_wrist_torque_successful[\u001b[38;5;241m2\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMax\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'columns'"
     ]
    }
   ],
   "source": [
    "# Use np.where to get out the indices. You can use == OR np.isclose() here; either works. In general, use .isclose for \n",
    "#  floating point comparisons.\n",
    "# Append the row number of any matches to this list\n",
    "all_rows_with_max = []\n",
    "\n",
    "\n",
    "# Look at JUST the z values in wrist_torque_data\n",
    "\n",
    "for c in range (len(ret_wrist_torque_successful.columns)):\n",
    "        for r in range (len(ret_wrist_torque_successful)):\n",
    "            if ret_wrist_torque_successful[r,c]==ret_wrist_torque_successful[2][\"Max\"]:\n",
    "                print(f\"row: {r}, time step:{c}\")\n",
    "# Pseudo code - see tutorial for exact format\n",
    "# for all row, column in all_indices_from_where\n",
    "#.   if this is row is successful \n",
    "#.      print(f\"Row: {r}, Time step: {c}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"optional_where\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Hours and collaborators\n",
    "Required for every assignment - fill out before you hand-in.\n",
    "\n",
    "Listing names and websites helps you to document who you worked with and what internet help you received in the case of any plagiarism issues. You should list names of anyone (in class or not) who has substantially helped you with an assignment - or anyone you have *helped*. You do not need to list TAs.\n",
    "\n",
    "Listing hours helps us track if the assignments are too long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# List of names (creates a set)\n",
    "worked_with_names = {\"none\"}\n",
    "# List of URLS TCW3 (creates a set)\n",
    "websites = {\"googled 'how to apply a 1d boolean to a 2d array'\"}\n",
    "# Approximate number of hours, including lab/in-class time\n",
    "hours = 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>hours_collaborators</pre></strong> passed! ✨</p>"
      ],
      "text/plain": [
       "hours_collaborators results: All test cases passed!"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"hours_collaborators\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**\n",
    "\n",
    "Submit just the .ipynb file to Gradescope (Lab 2 functions). You do not need to submit the data files. Don't change the provided variable names or autograding will fail. Look at the Gradescope grading rubric for code-quality checks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running your submission against local test cases...\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "c:\\Users\\yeasshhhh\\anaconda3\\Lib\\site-packages\\zmq\\_future.py:679: RuntimeWarning: Proactor event loop does not implement add_reader family of methods required for zmq. Registering an additional selector thread for add_reader support via tornado. Use `asyncio.set_event_loop_policy(WindowsSelectorEventLoopPolicy())` to avoid this warning.\r\n  self._get_loop()\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[102], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Save your notebook first, then run this cell to export your submission.\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m grader\u001b[38;5;241m.\u001b[39mexport(pdf\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, run_tests\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\yeasshhhh\\anaconda3\\Lib\\site-packages\\otter\\check\\utils.py:184\u001b[0m, in \u001b[0;36mgrading_mode_disabled\u001b[1;34m(wrapped, self, args, kwargs)\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m_grading_mode:\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 184\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\yeasshhhh\\anaconda3\\Lib\\site-packages\\otter\\check\\utils.py:166\u001b[0m, in \u001b[0;36mincompatible_with.<locals>.incompatible\u001b[1;34m(wrapped, self, args, kwargs)\u001b[0m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    165\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\yeasshhhh\\anaconda3\\Lib\\site-packages\\otter\\check\\utils.py:217\u001b[0m, in \u001b[0;36mlogs_event.<locals>.event_logger\u001b[1;34m(wrapped, self, args, kwargs)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_event(event_type, success\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, error\u001b[38;5;241m=\u001b[39me)\n\u001b[1;32m--> 217\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    219\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    220\u001b[0m     ret \u001b[38;5;241m=\u001b[39m LoggedEventReturnValue(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\yeasshhhh\\anaconda3\\Lib\\site-packages\\otter\\check\\utils.py:213\u001b[0m, in \u001b[0;36mlogs_event.<locals>.event_logger\u001b[1;34m(wrapped, self, args, kwargs)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;124;03mRuns a method, catching any errors and logging the call. Returns the unwrapped return value\u001b[39;00m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;124;03mof the wrapped function.\u001b[39;00m\n\u001b[0;32m    211\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 213\u001b[0m     ret: Optional[LoggedEventReturnValue[T]] \u001b[38;5;241m=\u001b[39m wrapped(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_event(event_type, success\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, error\u001b[38;5;241m=\u001b[39me)\n",
      "File \u001b[1;32mc:\\Users\\yeasshhhh\\anaconda3\\Lib\\site-packages\\otter\\check\\notebook.py:523\u001b[0m, in \u001b[0;36mNotebook.export\u001b[1;34m(self, nb_path, export_path, pdf, filtering, pagebreaks, files, display_link, force_save, run_tests)\u001b[0m\n\u001b[0;32m    520\u001b[0m         display(HTML(out_html))\n\u001b[0;32m    522\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pdf_created \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nbmeta_config\u001b[38;5;241m.\u001b[39mrequire_no_pdf_confirmation:\n\u001b[1;32m--> 523\u001b[0m     continue_export()\n\u001b[0;32m    524\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    525\u001b[0m     display_pdf_confirmation_widget(\n\u001b[0;32m    526\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nbmeta_config\u001b[38;5;241m.\u001b[39mexport_pdf_failure_message, continue_export)\n",
      "File \u001b[1;32mc:\\Users\\yeasshhhh\\anaconda3\\Lib\\site-packages\\otter\\check\\notebook.py:505\u001b[0m, in \u001b[0;36mNotebook.export.<locals>.continue_export\u001b[1;34m()\u001b[0m\n\u001b[0;32m    503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_tests:\n\u001b[0;32m    504\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning your submission against local test cases...\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 505\u001b[0m     results \u001b[38;5;241m=\u001b[39m grade_zip_file(zip_path, nb_path, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tests_dir)\n\u001b[0;32m    506\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYour submission received the following results when run against \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \\\n\u001b[0;32m    508\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mavailable test cases:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m indent(results\u001b[38;5;241m.\u001b[39msummary(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m    510\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m display_link:\n\u001b[0;32m    511\u001b[0m     \u001b[38;5;66;03m# create and display output HTML\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\yeasshhhh\\anaconda3\\Lib\\site-packages\\otter\\check\\utils.py:103\u001b[0m, in \u001b[0;36mgrade_zip_file\u001b[1;34m(zip_path, nb_arcname, tests_dir)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28mprint\u001b[39m(results\u001b[38;5;241m.\u001b[39mstdout\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m results\u001b[38;5;241m.\u001b[39mstderr:\n\u001b[1;32m--> 103\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(results\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(results_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    106\u001b[0m     results \u001b[38;5;241m=\u001b[39m dill\u001b[38;5;241m.\u001b[39mload(f)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: c:\\Users\\yeasshhhh\\anaconda3\\Lib\\site-packages\\zmq\\_future.py:679: RuntimeWarning: Proactor event loop does not implement add_reader family of methods required for zmq. Registering an additional selector thread for add_reader support via tornado. Use `asyncio.set_event_loop_policy(WindowsSelectorEventLoopPolicy())` to avoid this warning.\r\n  self._get_loop()\r\n"
     ]
    }
   ],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export(pdf=False, run_tests=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "boolean_slicing": {
     "name": "boolean_slicing",
     "points": 3,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert(np.isclose(z_min_successful, -0.293665094))\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert(np.isclose(z_max_successful, 0.340460618))\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert(np.isclose(z_min_unsuccessful, -0.62552044))\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert(np.isclose(z_max_unsuccessful, 0.326538637))\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "check_slice": {
     "name": "check_slice",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert(motor_effort_f1_data.shape == (n_picks, n_timesteps * n_dims_motor_effort_f1))\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert(wrist_torque_data.shape == (n_picks, n_timesteps * n_dims_wrist_torque))\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert(np.isclose(motor_effort_f1_data[0, 0], 0.0))\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert(np.isclose(motor_effort_f1_data[-1, -1], 51.11))\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "get_data": {
     "name": "get_data",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert(pick_channel_data.shape[0] == 660)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert(pick_channel_data.shape[1] == n_timesteps * n_total_dims)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert(np.count_nonzero(b_successful) == 355)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "hours_collaborators": {
     "name": "hours_collaborators",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert(not \"not filled out\" in worked_with_names)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert(not \"not filled out\" in websites)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert(hours > 0)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "loop_data_calc_stats": {
     "name": "loop_data_calc_stats",
     "points": 4,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert(len(ret_stats_array) == 3)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert(ret_stats_array[0][\"Mean\"] == 1.0)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert(ret_stats_array[1][\"Mean\"] == 2.0)\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert(ret_stats_array[2][\"Mean\"] == 3.0)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "optional_where": {
     "name": "optional_where",
     "points": 0,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert(all_rows_with_max[0] == 82)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "stats_channel": {
     "name": "stats_channel",
     "points": 4,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert(np.isclose(ret_dict[\"Min\"], 0.0))\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert(np.isclose(ret_dict[\"Max\"], 1.0))\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert(np.isclose(ret_dict[\"Mean\"], 0.5))\n",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert(np.isclose(ret_dict[\"SD\"], 0.319, atol=0.01))\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
